{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e314c5d-b26d-4ca6-856c-52110668149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import difflib\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "09f55267-61f3-4736-8d96-50052da574ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNGAN-DiffAug matched with SNGAN-DiffAug.yaml\n",
      "SNGAN-ADA matched with SNGAN-ADA.yaml\n",
      "SNGAN-APA matched with SNGAN-APA.yaml\n",
      "SNGAN-LeCam matched with SNGAN-LeCam.yaml\n",
      "SNGAN-DiffAug-LeCam matched with SNGAN-DiffAug-LeCam.yaml\n",
      "BigGAN-DiffAug matched with BigGAN-DiffAug.yaml\n",
      "BigGAN-ADA matched with BigGAN-ADA.yaml\n",
      "BigGAN-APA matched with BigGAN-APA.yaml\n",
      "BigGAN-LeCam matched with BigGAN-LeCam.yaml\n",
      "BigGAN-DiffAug-LeCam matched with BigGAN-DiffAug-LeCam.yaml\n",
      "StyleGAN2-DiffAug matched with StyleGAN2-DiffAug.yaml\n",
      "StyleGAN2-ADA matched with StyleGAN2-ADA.yaml\n",
      "StyleGAN2-APA matched with StyleGAN2-APA.yaml\n",
      "StyleGAN2-LeCam matched with StyleGAN2-LeCam.yaml\n",
      "StyleGAN2-DiffAug-LeCam matched with StyleGAN2-DiffAug-LeCam.yaml\n"
     ]
    }
   ],
   "source": [
    "# enter basic informations like checkpoint_path and configs_path\n",
    "\n",
    "ckpt_path = \"/root/ext_data/studiogan_ckpt/CIFAR10/checkpoints\"\n",
    "cfg_path = \"/root/code/joong/PyTorch-StudioGAN/src/configs/CIFAR10\"\n",
    "dataset_path = \"/root/ext_data/data/CIFAR10\"\n",
    "dataset = \"CIFAR10_efficient\"\n",
    "num_eval = 1\n",
    "\n",
    "ckpt_list = os.listdir(ckpt_path)\n",
    "cfg_list = os.listdir(cfg_path)\n",
    "\n",
    "# load Excel File and read informations\n",
    "wb = openpyxl.load_workbook(\"Taxonomy_experiments_offline.xlsx\")\n",
    "ws = wb['Efficient-CIFAR10-100%']\n",
    "\n",
    "runs = collections.defaultdict(lambda : collections.defaultdict(str))\n",
    "\n",
    "all_columns = ws.columns\n",
    "for idx,col in enumerate(all_columns):\n",
    "    if idx >=2 and col[1].value != None:\n",
    "        assert col[6].value in ckpt_list, str(col[6].value) + \" Not in ckpt_list\"\n",
    "        runs[col[1].value][\"run_1\"] = col[6].value\n",
    "        if col[7].value != None:\n",
    "            assert col[7].value in ckpt_list, str(col[7].value) + \" Not in ckpt_list\"\n",
    "            runs[col[1].value][\"run_2\"] = col[7].value\n",
    "        if col[8].value != None:\n",
    "            assert col[8].value in ckpt_list, str(col[8].value) + \" Not in ckpt_list\"\n",
    "            runs[col[1].value][\"run_3\"] = col[8].value\n",
    "            \n",
    "        if col[1].value == \"ACGAN\":\n",
    "            runs[col[1].value][\"cfg\"] = difflib.get_close_matches(col[1].value+\"-Mod\", cfg_list, n=1, cutoff=0)[0]\n",
    "        else:\n",
    "            runs[col[1].value][\"cfg\"] = difflib.get_close_matches(col[1].value, cfg_list, n=1, cutoff=0)[0]\n",
    "        print(f\"{col[1].value} matched with {runs[col[1].value]['cfg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f2312a69-baaf-4741-b6f9-58726dadfd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After fixing...\n",
      "SNGAN-DiffAug matched with SNGAN-DiffAug.yaml\n",
      "SNGAN-ADA matched with SNGAN-ADA.yaml\n",
      "SNGAN-APA matched with SNGAN-APA.yaml\n",
      "SNGAN-LeCam matched with SNGAN-LeCam.yaml\n",
      "SNGAN-DiffAug-LeCam matched with SNGAN-DiffAug-LeCam.yaml\n",
      "BigGAN-DiffAug matched with BigGAN-DiffAug.yaml\n",
      "BigGAN-ADA matched with BigGAN-ADA.yaml\n",
      "BigGAN-APA matched with BigGAN-APA.yaml\n",
      "BigGAN-LeCam matched with BigGAN-LeCam.yaml\n",
      "BigGAN-DiffAug-LeCam matched with BigGAN-DiffAug-LeCam.yaml\n",
      "StyleGAN2-DiffAug matched with StyleGAN2-DiffAug.yaml\n",
      "StyleGAN2-ADA matched with StyleGAN2-ADA.yaml\n",
      "StyleGAN2-APA matched with StyleGAN2-APA.yaml\n",
      "StyleGAN2-LeCam matched with StyleGAN2-LeCam.yaml\n",
      "StyleGAN2-DiffAug-LeCam matched with StyleGAN2-DiffAug-LeCam.yaml\n"
     ]
    }
   ],
   "source": [
    "# Check if evey excel column is matched with proper configurations and modify config if needed.\n",
    "# runs[\"TACGAN\"][\"cfg\"] = \"ACGAN-Mod-TAC.yaml\"\n",
    "# runs[\"CRGAN\"][\"cfg\"] = \"BigGAN-CR.yaml\"\n",
    "# runs[\"ICRGAN\"][\"cfg\"] = \"BigGAN-ICR.yaml\"\n",
    "# runs[\"ADCGAN\"][\"cfg\"] = \"ACGAN-Mod-Big-ADC.yaml\"\n",
    "# runs[\"BigGAN-LeCam\"][\"cfg\"] = \"BigGAN-256Res-LeCam.yaml\"\n",
    "# runs[\"StyleGAN2-LeCam\"][\"cfg\"] = \"StyleGAN2-256Res-LeCam.yaml\"\n",
    "\n",
    "print(\"After fixing...\")\n",
    "for key, value in runs.items():\n",
    "    print(f\"{key} matched with {value['cfg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "66dbfb49-826f-48ae-a26e-9adb6e6af8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write script file\n",
    "i = 1\n",
    "with open(\"eval_\"+dataset+\".sh\", \"w\") as f:\n",
    "    f.write(\"wandb offline\\n\")\n",
    "    train_ = \" -ref train \"\n",
    "    metrics_full = \" -metrics is fid prdc \"\n",
    "    metrics_fide = \" -metrics is fid \"\n",
    "    eval_backbone_incep = \" --eval_backbone InceptionV3_tf \"\n",
    "    eval_backbone_swav = \" --eval_backbone SwAV_torch \"\n",
    "    eval_backbone_swin = \" --eval_backbone Swin-T_torch \"\n",
    "    \n",
    "    if dataset == \"ImageNet\":\n",
    "        prefix_ = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 256 -std_step 256 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc -DDP\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref valid \"\n",
    "    elif dataset in [\"Baby_ImageNet\", \"Papa_ImageNet\", \"Grandpa_ImageNet\", \"AFHQv2\"]:\n",
    "        prefix_S = \"CUDA_VISIBLE_DEVICES=0,1,2,3 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 256 -std_step 256 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_B = \"CUDA_VISIBLE_DEVICES=0,1,2,3 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 1024 -std_step 1024 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc -DDP\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref valid \"\n",
    "    elif dataset == \"CIFAR10\":\n",
    "        prefix_ = \"CUDA_VISIBLE_DEVICES=0 python src/main.py --pre_resizer wo_resize --post_resizer tailored -std_stat -std_max 128 -std_step 128 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0 python src/main.py --pre_resizer wo_resize --post_resizer tailored -best --seed 1234 -mpc\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref test \"\n",
    "    \n",
    "    for (key, value) in runs.items():\n",
    "        others1 = \" -ckpt \" + os.path.join(ckpt_path, value['run_1']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        if value['run_2'] != '':\n",
    "            others2 = \" -ckpt \" + os.path.join(ckpt_path, value['run_2']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        else:\n",
    "            others2 = None\n",
    "        if value['run_3'] != '':\n",
    "            others3 = \" -ckpt \" + os.path.join(ckpt_path, value['run_3']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        else:\n",
    "            others3 = None\n",
    "        \n",
    "        if \"Style\" in key:\n",
    "            prefix = prefix_style\n",
    "        elif dataset in [\"Baby_ImageNet\",\"Papa_ImageNet\", \"Grandpa_ImageNet\", \"AFHQv2\"] and (\"SAGAN\" in key or \"SNGAN\" in key):\n",
    "            prefix = prefix_S\n",
    "        elif dataset in [\"Baby_ImageNet\",\"Papa_ImageNet\", \"Grandpa_ImageNet\", \"AFHQv2\"] and (\"BigGAN\" in key or \"ContraGAN\" in key or \"ReACGAN\" in key):\n",
    "            prefix = prefix_B\n",
    "        else:\n",
    "            prefix = prefix_\n",
    "        \n",
    "        for other in [others1, others2, others3]:\n",
    "            if other != None:\n",
    "                f.write(prefix + other + eval_backbone_incep + metrics_fide + eval_ + \"\\n\")\n",
    "                f.write(f\"echo =================={i}/{60} completed =============\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swav + metrics_full + train_+ \"\\n\")\n",
    "                f.write(f\"echo =================={i}/{60} completed =============\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swav + metrics_fide + eval_+ \"\\n\")\n",
    "                f.write(f\"echo =================={i}/{60} completed =============\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swin + metrics_full + train_+ \"\\n\")\n",
    "                f.write(f\"echo =================={i}/{60} completed =============\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swin + metrics_fide + eval_+ \"\\n\")\n",
    "                f.write(f\"echo =================={i}/{60} completed =============\\n\")\n",
    "                i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03686d-c913-43d9-a558-7cde820fb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RUN \n",
    "#### bash eval_clean_CIFAR10.sh\n",
    "#### bash eval....sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed21e9-492f-4496-9a13-380b07a801d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"/root/code/joong/PyTorch-StudioGAN/eval_pickles/DCGAN-train-2022_01_11_20_32_07---clean.pickle\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74ae46-f352-456a-9268-6269c5f437a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)\n",
    "print(float(data[\"IS\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274ad34-9814-41e2-acd9-e5f297926c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_excel(col, start_row, data):\n",
    "    col[start_row].value = float(data[\"IS\"])\n",
    "    col[start_row+4].value = data[\"FID\"]\n",
    "    col[start_row+8].value = data[\"Improved_Precision\"]\n",
    "    col[start_row+12].value = data[\"Improved_Recall\"]\n",
    "    col[start_row+16].value = data[\"Density\"]\n",
    "    col[start_row+20].value = data[\"Coverage\"]\n",
    "    \n",
    "def modify_name(col, resize_fn):\n",
    "    if col[6].value == \"CIFAR10-BigGAN-Deep-train-2022_02_02_21_56_10\":\n",
    "        name1 = \"BigGAN-Deep-StudioGAN-train-2022_02_02_21_56_10\"+ \"---\"+resize_fn+\".pickle\"\n",
    "        name2 = \"BigGAN-Deep-StudioGAN-train-2022_02_02_21_56_49\"+ \"---\"+resize_fn+\".pickle\"\n",
    "        name3 = \"BigGAN-Deep-StudioGAN-train-2022_02_02_22_01_49\"+ \"---\"+resize_fn+\".pickle\"\n",
    "    elif col[6].value[8:].startswith(\"BigGAN-Mod\"):\n",
    "        name1 = col[6].value[8:][0:6]+col[6].value[8:][10:]+ \"---\"+resize_fn+\".pickle\"\n",
    "        name2 = col[7].value[8:][0:6]+col[7].value[8:][10:]+ \"---\"+resize_fn+\".pickle\"\n",
    "        name3 = col[8].value[8:][0:6]+col[8].value[8:][10:]+ \"---\"+resize_fn+\".pickle\"\n",
    "    else:\n",
    "        name1 = col[6].value[8:] + \"---\"+resize_fn+\".pickle\"\n",
    "        name2 = col[7].value[8:] + \"---\"+resize_fn+\".pickle\"\n",
    "        name3 = col[8].value[8:] + \"---\"+resize_fn+\".pickle\"\n",
    "    return name1, name2, name3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d5b3c-520c-4465-9738-0493723b105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Excel File and read informations\n",
    "wb_clean = openpyxl.load_workbook(\"CIFAR10_clean.xlsx\")\n",
    "ws_clean = wb_clean['Sheet1']\n",
    "pickles_path = \"/root/code/joong/PyTorch-StudioGAN/eval_pickles/\"\n",
    "pickles_list = os.listdir(pickles_path)\n",
    "\n",
    "all_columns = ws_clean.columns\n",
    "for idx,col in enumerate(all_columns):\n",
    "    if idx >=2 and col[1].value != None:\n",
    "        name1, name2, name3 = modify_name(col, \"clean\")\n",
    "        assert name1 in pickles_list, name1 + \" Pickle Does not exist\"\n",
    "        assert name2 in pickles_list, name2 + \" Pickle Does not exist\"\n",
    "        assert name3 in pickles_list, name3 + \" Pickle Does not exist\"\n",
    "\n",
    "        with open(os.path.join(pickles_path, name1), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 10, data)\n",
    "        with open(os.path.join(pickles_path, name2), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 11, data)\n",
    "        with open(os.path.join(pickles_path, name3), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 12, data)\n",
    "wb_clean.save(\"CIFAR10_clean.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207ee86-5e31-43ec-a912-8e14c960cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Excel File and read informations\n",
    "wb_legacy = openpyxl.load_workbook(\"CIFAR10_legacy.xlsx\")\n",
    "ws_legacy = wb_legacy['Sheet1']\n",
    "pickles_path = \"/root/code/joong/PyTorch-StudioGAN/eval_pickles/\"\n",
    "pickles_list = os.listdir(pickles_path)\n",
    "\n",
    "all_columns = ws_legacy.columns\n",
    "for idx,col in enumerate(all_columns):\n",
    "    if idx >=2 and col[1].value != None:\n",
    "        name1, name2, name3 = modify_name(col, \"legacy\")\n",
    "        assert name1 in pickles_list, name1 + \" Pickle Does not exist\"\n",
    "        assert name2 in pickles_list, name2 + \" Pickle Does not exist\"\n",
    "        assert name3 in pickles_list, name3 + \" Pickle Does not exist\"\n",
    "\n",
    "        with open(os.path.join(pickles_path, name1), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 10, data)\n",
    "        with open(os.path.join(pickles_path, name2), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 11, data)\n",
    "        with open(os.path.join(pickles_path, name3), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            fill_excel(col, 12, data)\n",
    "wb_legacy.save(\"CIFAR10_legacy.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce56ee-75e4-4a16-b45a-a7aa328d65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "pickles_path = \"/root/code/joong/PyTorch-StudioGAN/eval_pickles/\"\n",
    "pickles_list = sorted(os.listdir(pickles_path))\n",
    "for item in pickles_list:\n",
    "    if item.endswith(\"le\"):\n",
    "        with open(pickles_path+str(item), \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "            if data == {}:\n",
    "                print(item[:-7])\n",
    "            # if \"Improved_Precision\" not in data.keys():\n",
    "            #     print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf3d6d2-3af3-4c1d-b528-d5b19e26eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickles_path = \"/root/code/joong/PyTorch-StudioGAN/eval_pickles/\"\n",
    "pickles_list = sorted(os.listdir(pickles_path))\n",
    "\n",
    "for item in pickles_list:\n",
    "    if item.endswith(\".pickle\"):\n",
    "        os.rename(pickles_path+item, pickles_path+item[:-7]+\"-train.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c70e7-30b2-4ba1-9d84-7c9efc59e3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter basic informations like checkpoint_path and configs_path,\n",
    "# load Excel File and read informations\n",
    "import openpyxl\n",
    "wb = openpyxl.load_workbook(\"Taxonomy_experiments_offline.xlsx\")\n",
    "ws = wb['Efficient-AFHQ-V2']\n",
    "dataset_name = 'AFHQv2-'\n",
    "pickles_path = \"/root/code/joong/PyTorch-StudioGAN/eval_pickles/\"\n",
    "pickles_list = sorted(os.listdir(pickles_path))\n",
    "\n",
    "all_columns = ws.columns\n",
    "for idx,col in enumerate(all_columns):\n",
    "    if idx >=2 and col[1].value != None:\n",
    "        run_name1 = col[6].value[len(dataset_name):]\n",
    "        run_name2 = col[7].value[len(dataset_name):] if col[7].value is not None else None\n",
    "        run_name3 = col[8].value[len(dataset_name):] if col[8].value is not None else None\n",
    "        for run_name  in [run_name1, run_name2, run_name3]:\n",
    "            if run_name is not None:\n",
    "                if run_name + \".pickle\" in pickles_list:\n",
    "                    os.rename(pickles_path + run_name + \".pickle\", pickles_path + dataset_name + run_name + \".pickle\")\n",
    "                elif dataset_name + run_name + \".pickle\" in pickles_list:\n",
    "                    pass\n",
    "                else:\n",
    "                    print(\"error\", run_name + \".pickle\" , \"not in pickles_list\")\n",
    "        \n",
    "            \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
