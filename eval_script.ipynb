{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e314c5d-b26d-4ca6-856c-52110668149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import difflib\n",
    "import collections\n",
    "from datetime import datetime\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f55267-61f3-4736-8d96-50052da574ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/root/ext_data/studiogan_ckpt/AFHQv2_uncond_512/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAFHQv2_uncond_512\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m num_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m----> 9\u001b[0m ckpt_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m cfg_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(cfg_path)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# load Excel File and read informations\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/ext_data/studiogan_ckpt/AFHQv2_uncond_512/checkpoints'"
     ]
    }
   ],
   "source": [
    "# enter basic informations like checkpoint_path and configs_path\n",
    "\n",
    "ckpt_path = \"/root/ext_data/studiogan_ckpt/AFHQv2_uncond_512/checkpoints\"\n",
    "cfg_path = \"./src/configs/AFHQv2_uncond_512\"\n",
    "dataset_path = \"/root/code/joong/data/AFHQv2_uncond_512\"\n",
    "dataset = \"AFHQv2_uncond_512\"\n",
    "num_eval = 1\n",
    "\n",
    "ckpt_list = os.listdir(ckpt_path)\n",
    "cfg_list = os.listdir(cfg_path)\n",
    "\n",
    "# load Excel File and read informations\n",
    "wb = openpyxl.load_workbook(\"Taxonomy_experiments_offline.xlsx\")\n",
    "ws = wb['AFHQ-V2-512-uncond-tailored']\n",
    "\n",
    "runs = collections.defaultdict(lambda : collections.defaultdict(str))\n",
    "\n",
    "all_columns = ws.columns\n",
    "for idx,col in enumerate(all_columns):\n",
    "    if idx >=2 and col[1].value != None:\n",
    "        assert col[6].value in ckpt_list, str(col[6].value) + \" Not in ckpt_list\"\n",
    "        runs[col[1].value][\"run_1\"] = col[6].value\n",
    "        if col[7].value != None:\n",
    "            assert col[7].value in ckpt_list, str(col[7].value) + \" Not in ckpt_list\"\n",
    "            runs[col[1].value][\"run_2\"] = col[7].value\n",
    "        if col[8].value != None:\n",
    "            assert col[8].value in ckpt_list, str(col[8].value) + \" Not in ckpt_list\"\n",
    "            runs[col[1].value][\"run_3\"] = col[8].value\n",
    "            \n",
    "        if col[1].value == \"ACGAN\":\n",
    "            runs[col[1].value][\"cfg\"] = difflib.get_close_matches(col[1].value+\"-Mod\", cfg_list, n=1, cutoff=0)[0]\n",
    "        else:\n",
    "            runs[col[1].value][\"cfg\"] = difflib.get_close_matches(col[1].value, cfg_list, n=1, cutoff=0)[0]\n",
    "        print(f\"{col[1].value} matched with {runs[col[1].value]['cfg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2312a69-baaf-4741-b6f9-58726dadfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if evey excel column is matched with proper configurations and modify config if needed.\n",
    "# runs[\"TACGAN\"][\"cfg\"] = \"ACGAN-Mod-TAC.yaml\"\n",
    "# runs[\"CRGAN\"][\"cfg\"] = \"BigGAN-CR.yaml\"\n",
    "# runs[\"ICRGAN\"][\"cfg\"] = \"BigGAN-ICR.yaml\"\n",
    "# runs[\"ADCGAN\"][\"cfg\"] = \"ACGAN-Mod-Big-ADC.yaml\"\n",
    "# runs[\"BigGAN-LeCam\"][\"cfg\"] = \"BigGAN-256Res-LeCam.yaml\"\n",
    "# runs[\"StyleGAN2-LeCam\"][\"cfg\"] = \"StyleGAN2-256Res-LeCam.yaml\"\n",
    "\n",
    "print(\"After fixing...\")\n",
    "for key, value in runs.items():\n",
    "    print(f\"{key} matched with {value['cfg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dbfb49-826f-48ae-a26e-9adb6e6af8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write script file\n",
    "i = 1\n",
    "with open(\"eval_\"+dataset+\".sh\", \"w\") as f:\n",
    "    f.write(\"wandb offline\\n\")\n",
    "    train_ = \" -ref train \"\n",
    "    metrics_full = \" -metrics is fid prdc -ifid \"\n",
    "    metrics_fide = \" -metrics is fid \"\n",
    "    eval_backbone_incep = \" --eval_backbone InceptionV3_tf \"\n",
    "    eval_backbone_swav = \" --eval_backbone SwAV_torch \"\n",
    "    eval_backbone_swin = \" --eval_backbone Swin-T_torch \"\n",
    "    \n",
    "    if dataset == \"ImageNet\":\n",
    "        prefix_ = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 256 -std_step 256 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc -DDP\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref valid \"\n",
    "    elif dataset in [\"Baby_ImageNet\", \"Papa_ImageNet\", \"Grandpa_ImageNet\"]:\n",
    "        prefix_S = \"CUDA_VISIBLE_DEVICES=0,1,2,3 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 256 -std_step 256 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_B = \"CUDA_VISIBLE_DEVICES=0,1,2,3 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 1024 -std_step 1024 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc -DDP\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref valid \"\n",
    "    elif dataset ==  \"AFHQv2\":\n",
    "        prefix_ = \"CUDA_VISIBLE_DEVICES=0,1,2,3 python src/main.py --pre_resizer lanczos --post_resizer tailored -sync_bn -std_stat -std_max 256 -std_step 256 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0,1 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc -DDP\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref valid \"\n",
    "    elif dataset == \"AFHQv2_uncond_512\":\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0 python src/main.py --pre_resizer lanczos --post_resizer tailored -best --seed 1234 -mpc\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "    elif dataset.startswith(\"CIFAR10\"):\n",
    "        prefix_ = \"CUDA_VISIBLE_DEVICES=0 python src/main.py --pre_resizer wo_resize --post_resizer tailored -std_stat -std_max 128 -std_step 128 -best --seed 1234\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        prefix_style = \"CUDA_VISIBLE_DEVICES=0 python src/main.py --pre_resizer wo_resize --post_resizer tailored -best --seed 1234 -mpc\" + \" -data \" + dataset_path + \" -save ../studiogan/\" + \" --num_eval \" + str(num_eval)\n",
    "        eval_ = \" -ref test \"\n",
    "    \n",
    "    for (key, value) in runs.items():\n",
    "        others1 = \" -ckpt \" + os.path.join(ckpt_path, value['run_1']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        if value['run_2'] != '':\n",
    "            others2 = \" -ckpt \" + os.path.join(ckpt_path, value['run_2']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        else:\n",
    "            others2 = None\n",
    "        if value['run_3'] != '':\n",
    "            others3 = \" -ckpt \" + os.path.join(ckpt_path, value['run_3']) + \" -cfg \" + os.path.join(cfg_path, value['cfg'])\n",
    "        else:\n",
    "            others3 = None\n",
    "        \n",
    "        if \"Style\" in key:\n",
    "            prefix = prefix_style\n",
    "        elif dataset in [\"Baby_ImageNet\",\"Papa_ImageNet\", \"Grandpa_ImageNet\"] and (\"SAGAN\" in key or \"SNGAN\" in key):\n",
    "            prefix = prefix_S\n",
    "        elif dataset in [\"Baby_ImageNet\",\"Papa_ImageNet\", \"Grandpa_ImageNet\"] and (\"BigGAN\" in key or \"ContraGAN\" in key or \"ReACGAN\" in key):\n",
    "            prefix = prefix_B\n",
    "        else:\n",
    "            prefix = prefix_\n",
    "        \n",
    "        for other in [others1, others2, others3]:\n",
    "            if other != None:\n",
    "                f.write(prefix + other + eval_backbone_incep + metrics_full + train_ + \"\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swav + metrics_full + train_+ \"\\n\")\n",
    "                i+=1 \n",
    "                f.write(prefix + other + eval_backbone_swin + metrics_full + train_+ \"\\n\")\n",
    "                i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f03686d-c913-43d9-a558-7cde820fb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RUN \n",
    "#### bash eval_clean_CIFAR10.sh\n",
    "#### bash eval....sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9274ad34-9814-41e2-acd9-e5f297926c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_values(col, start):\n",
    "    tmp = []\n",
    "    for i in range(3):\n",
    "        if col[start+i].value != None:\n",
    "            tmp.append(col[start+i].value)\n",
    "    return tmp\n",
    "\n",
    "def fill_excel_train(col, start_row, data):\n",
    "    col[start_row].value = float(data[\"IS\"])\n",
    "    col[start_row+4].value = data[\"FID\"]\n",
    "    col[start_row+8].value = data[\"Improved_Precision\"]\n",
    "    col[start_row+12].value = data[\"Improved_Recall\"]\n",
    "    col[start_row+16].value = data[\"Density\"]\n",
    "    col[start_row+20].value = data[\"Coverage\"]\n",
    "    \n",
    "def fill_excel_valid(col, start_row, data):\n",
    "    col[start_row].value = data[\"FID\"]\n",
    "def fill_excel_ifid(col, start_row, data):\n",
    "    col[start_row].value = sum(data)/len(data)\n",
    "def fill_excel_extra(col):\n",
    "    pairs = [(10, 107), (42,134), (74,161)]\n",
    "    for pair in pairs:\n",
    "        for i in range(8):\n",
    "            tmp = accumulate_values(col, pair[0]+4*i)\n",
    "            if len(tmp) == 0:\n",
    "                col[pair[1]+3*i].value = None\n",
    "                col[pair[1]+3*i+1].value = None\n",
    "            elif len(tmp) == 1:\n",
    "                col[pair[1]+3*i].value = round(np.mean(tmp),2)\n",
    "                col[pair[1]+3*i+1].value = \"*\"\n",
    "            else:\n",
    "                col[pair[1]+3*i].value = round(np.mean(tmp),2)\n",
    "                col[pair[1]+3*i+1].value = round(np.std(tmp, ddof=0),3)\n",
    "\n",
    "def check_SN(name):\n",
    "    if name.startswith(\"CIFAR10-SNGAN-Diff\"):\n",
    "        return False\n",
    "    if name.startswith(\"CIFAR10-SNGAN-ADA\"):\n",
    "        return False\n",
    "    if name.startswith(\"CIFAR10-SNGAN-APA\"):\n",
    "        return False\n",
    "    if name.startswith(\"CIFAR10-SNGAN-LeCam\"):\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def get_value(col, row):\n",
    "    if col[row].value != None:\n",
    "        return col[row].value\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def get_pickle_names(col):\n",
    "    pickle_names = defaultdict(dict)\n",
    "    run_name1, run_name2, run_name3 = col[6].value, None, None\n",
    "    if not run_name1.startswith(\"CIFAR10_\") and check_SN(run_name1):\n",
    "        backbones = [\"InceptionV3_tf\", \"SwAV_torch\", \"Swin-T_torch\"]\n",
    "    else:\n",
    "        backbones = [\"InceptionV3_tf\"]\n",
    "\n",
    "    valid = \"test\" if run_name1.startswith(\"CIFAR\") else \"valid\"\n",
    "    if col[7].value != None:\n",
    "        run_name2 = col[7].value\n",
    "    if col[8].value != None:\n",
    "        run_name3 = col[8].value\n",
    "    for i, run_name in enumerate([run_name1, run_name2, run_name3]):\n",
    "        if run_name != None:\n",
    "            for backbone in backbones:\n",
    "                pickle_names[f\"run_name{i+1}\"][f\"{backbone}-train\"] = run_name+f\"-{backbone}-train.pickle\"\n",
    "                if not run_name.startswith(\"CIFAR10_\") and check_SN(run_name):\n",
    "                    pickle_names[f\"run_name{i+1}\"][f\"{backbone}-ifid\"] = run_name+f\"-{backbone}-train-ifid.pickle\"\n",
    "                    if not run_name.startswith(\"AFHQ_V2_uncond\"):\n",
    "                        pickle_names[f\"run_name{i+1}\"][f\"{backbone}-valid\"] = run_name+f\"-{backbone}-{valid}.pickle\"\n",
    "    return pickle_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "408d5b3c-520c-4465-9738-0493723b105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Excel File and read informations\n",
    "import openpyxl\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "wb = openpyxl.load_workbook(\"Taxonomy_experiments_offline.xlsx\")\n",
    "pickles_path = \"./eval_pickles/\"\n",
    "pickles_list = os.listdir(pickles_path)\n",
    "ws_list = [\"AFHQ-V2-512-uncond-tailored\", \"CIFAR10_tailored\", \"ImageNet_tailored\", \"Baby_ImageNet_tailored\", \"Papa_ImageNet_tailored\", \"Grandpa_ImageNet_tailored\", \"Efficient-AFHQ-V2-256\", \"Efficient-CIFAR10-100%\", \"Efficient-CIFAR10-30%\", \"Efficient-CIFAR10-10%\"]\n",
    "IS_start_row = 10\n",
    "SwAV_start_row = 42\n",
    "SwinT_start_row = 74\n",
    "\n",
    "for ws in ws_list:\n",
    "    ws = wb[ws]\n",
    "    all_columns = ws.columns\n",
    "    \n",
    "    for idx, col in enumerate(all_columns):        \n",
    "        if idx >=2 and col[1].value != None:\n",
    "            pickle_names = get_pickle_names(col)\n",
    "            \n",
    "            for i, key in enumerate(pickle_names.keys()): \n",
    "                # i, key = run_name1,2,3\n",
    "                for key, value in pickle_names[key].items():\n",
    "                    # key = \"backbone-train/valid/ifid\", value = \"~~.pickle\"\n",
    "                    \n",
    "                    # get starting row\n",
    "                    if key.startswith(\"Inc\"):\n",
    "                        start_row = IS_start_row\n",
    "                    elif key.startswith(\"SwAV\"):\n",
    "                        start_row = SwAV_start_row\n",
    "                    else:\n",
    "                        start_row = SwinT_start_row\n",
    "                        \n",
    "                    with open(os.path.join(pickles_path, value), \"rb\") as f:\n",
    "                        data = pickle.load(f)\n",
    "                        if key.endswith(\"train\"):\n",
    "                            fill_excel_train(col, start_row + i, data)\n",
    "                        if key.endswith(\"valid\"):\n",
    "                            fill_excel_valid(col, start_row + i + 24, data)\n",
    "                        if key.endswith(\"ifid\"):\n",
    "                            fill_excel_ifid(col, start_row + i + 28, data)\n",
    "    \n",
    "    # fill average and stds\n",
    "    all_columns = ws.columns\n",
    "    fid_inc, fid_swav, fid_swin = [], [], []\n",
    "    efid_inc, efid_swav, efid_swin = [], [], []\n",
    "    is_inc, is_swav, is_swin = [], [], []\n",
    "    ifid_inc, ifid_swav, ifid_swin = [], [], []\n",
    "    \n",
    "    for idx, col in enumerate(all_columns):\n",
    "        if idx >= 2 and col[1].value != None:\n",
    "            fill_excel_extra(col)\n",
    "            \n",
    "            for idx, backbone in enumerate([is_inc, is_swav, is_swin]):\n",
    "                if col[107+27*idx].value != None:\n",
    "                    backbone.append(col[107+27*idx].value)  \n",
    "                    \n",
    "            for idx, backbone in enumerate([fid_inc, fid_swav, fid_swin]):\n",
    "                if col[110+27*idx].value != None:\n",
    "                    backbone.append(col[110+27*idx].value)  \n",
    "                    \n",
    "            for idx, backbone in enumerate([efid_inc, efid_swav, efid_swin]):\n",
    "                if col[125+27*idx].value != None:\n",
    "                    backbone.append(col[125+27*idx].value)   \n",
    "                    \n",
    "            for idx, backbone in enumerate([ifid_inc, ifid_swav, ifid_swin]):\n",
    "                if col[128+27*idx].value != None:\n",
    "                    backbone.append(col[128+27*idx].value)            \n",
    "                \n",
    "    \n",
    "    # fill fid rank\n",
    "    all_columns = ws.columns\n",
    "    for idx, col in enumerate(all_columns):\n",
    "        if idx >= 2 and col[1].value != None:\n",
    "            for idx, backbone in enumerate([is_inc, is_swav, is_swin]):\n",
    "                if col[107+27*idx].value != None:\n",
    "                    col[131+27*idx].value = sorted(backbone, reverse=True).index(col[107+27*idx].value)+1\n",
    "\n",
    "            for idx, backbone in enumerate([fid_inc, fid_swav, fid_swin]):\n",
    "                if col[110+27*idx].value != None:\n",
    "                    col[132+27*idx].value = sorted(backbone).index(col[110+27*idx].value)+1\n",
    "                    \n",
    "            for idx, backbone in enumerate([efid_inc, efid_swav, efid_swin]):\n",
    "                if col[125+27*idx].value != None:\n",
    "                    col[133+27*idx].value = sorted(backbone).index(col[125+27*idx].value)+1\n",
    "            \n",
    "            \n",
    "            for idx, backbone in enumerate([ifid_inc, ifid_swav, ifid_swin]):\n",
    "                if col[128+27*idx].value != None:\n",
    "                    col[133+27*idx].value = f\"{col[133+27*idx].value} / {sorted(backbone).index(col[128+27*idx].value)+1}\"\n",
    "            \n",
    "wb.save(\"Taxonomy_experiments_offline.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
